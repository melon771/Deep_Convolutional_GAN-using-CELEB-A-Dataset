# Deep Convolutional GAN using CelebA Dataset

This project implements a **Deep Convolutional Generative Adversarial Network (DCGAN)** to generate realistic-looking face images from the **CelebA** dataset. It follows the architecture and methodology inspired by the well-known DCGAN model and trains a generator and discriminator to compete in a minimax game, improving the quality of generated images.

## Project Inspiration

This project draws inspiration from the tutorial on building DCGANs shared by **Rohan Paul**, available [here](https://github.com/rohan-paul/MachineLearning-DeepLearning-Code-for-my-YouTube-Channel/blob/master/Computer_Vision/DCGAN%20from%20Scratch%20with%20TensorFlow%20-%20Generate%20fake%20Faces%20from%20CelebA%20Dataset/DCGAN_with_Tensorflow_Keras_Celeb_A_Dataset.ipynb). The tutorial provides a detailed explanation of how to build a DCGAN model using TensorFlow and the CelebA dataset. This project is inspired by the same but is developed independently with certain modifications to suit my learning and implementation style.

## What is a DCGAN?

A **Deep Convolutional Generative Adversarial Network (DCGAN)** is a type of GAN (Generative Adversarial Network) where the generator and discriminator networks are built using deep convolutional layers. The GAN framework consists of two main models:

1. **Generator**: 
   - The generator takes random noise (a latent vector) as input and transforms it into a synthetic image that mimics the real data. 
   - The goal of the generator is to create fake images that are convincing enough to fool the discriminator into believing they are real.

2. **Discriminator**: 
   - The discriminator is a binary classifier that takes an image (either real or fake) as input and attempts to determine whether it is a real image from the training dataset or a fake image produced by the generator.
   - The discriminator's job is to correctly classify real and fake images.

The two networks are trained simultaneously in a minimax game:
- The generator tries to improve its ability to produce realistic images.
- The discriminator tries to improve its ability to distinguish real images from fake ones.

The competition between the generator and the discriminator pushes both models to improve until the generator produces highly realistic images that the discriminator cannot easily distinguish from real images.

### Why Convolutional Layers?
In **DCGANs**, convolutional layers are used because they are particularly good at processing image data. They enable the network to capture spatial hierarchies and features, such as edges and textures, which are important for generating realistic images.

## How This Project Works

### 1. **Data Preparation**
   - We use the **CelebA** dataset, which contains over 200,000 celebrity face images. These images vary in facial attributes such as age, gender, and expressions.
   - Before training the model, we preprocess the images to normalize the pixel values and resize them to a fixed size (64x64x3) to ensure uniformity.

### 2. **DCGAN Architecture**

#### Generator
The generator model uses **transposed convolutional layers** (also known as deconvolution layers) to transform a random noise vector (sampled from a uniform distribution) into an image. The key layers in the generator are:
- **Dense Layer**: Takes the noise as input and reshapes it into a small tensor.
- **Transposed Convolution Layers**: Upsample the tensor back into an image shape (64x64x3).
- **Batch Normalization**: Used to stabilize training and allow for faster convergence.
- **Leaky ReLU Activation**: Used to introduce non-linearity and prevent dead neurons.
- **Tanh Activation**: The final layer uses `tanh` to scale the output image to the range of [-1, 1].

#### Discriminator
The discriminator model is a standard **convolutional neural network (CNN)**, used to classify input images as real or fake. The key components are:
- **Convolutional Layers**: Extract features from the input image.
- **Batch Normalization**: Helps in stabilizing and speeding up the training.
- **Leaky ReLU Activation**: Prevents neurons from dying during training.
- **Sigmoid Activation**: The final layer uses a sigmoid activation to produce a probability (0 or 1) indicating whether the image is real or fake.

### 3. **Training Process**

- During each training iteration:
   1. We feed a batch of real images from the CelebA dataset to the discriminator, labeled as real (`1`).
   2. We feed a batch of fake images generated by the generator to the discriminator, labeled as fake (`0`).
   3. The generator is trained to produce images that can fool the discriminator. It does this by optimizing the adversarial loss, which is designed to trick the discriminator into classifying generated images as real.

- **Loss Functions**:
   - The discriminator's loss function encourages it to distinguish real images from fake images.
   - The generator's loss function encourages it to fool the discriminator into classifying its output as real.

- **Optimization**: We use the **Adam optimizer** with a learning rate of `0.0002` for both the generator and the discriminator. The learning rate and optimizers can be modified for better results.

### 4. **Evaluating the Model**
   - As the training progresses, the quality of the images generated by the generator improves. We can periodically generate and visualize samples to manually inspect the image quality.
   - The generator learns to create images that become more realistic as training proceeds.

### 5. **Stopping Criteria**
   - The training can be stopped when the images generated by the generator are sufficiently realistic.
   - We can also set a maximum number of epochs to run the training and save model checkpoints at intervals.

## Project Structure

├── README.md                <- You are here
├── CelebA_Dataset           <- Folder containing the CelebA dataset
├── DCGAN_Model              <- Code files for the DCGAN model
│   ├── generator.py         <- Generator model definition
│   ├── discriminator.py     <- Discriminator model definition
│   └── dcgan.py             <- Training script for DCGAN
├── utils.py                 <- Utility functions for data preprocessing, etc.
└── results                  <- Folder to save generated images during training

Requirements
Python 3.7+
TensorFlow 2.x
NumPy
Matplotlib
CelebA Dataset
Install the necessary packages using:

bash
Copy code
pip install -r requirements.txt
Dataset
The CelebA dataset is used for training the GAN model. It contains over 200,000 celebrity face images with varying facial attributes. You can download the dataset from the official CelebA website.

How to Run the Project
Clone the repository and navigate into the project directory:

bash
Copy code
git clone https://github.com/concise-Sthita/Deep_Convolutional_GAN-using-CELEB-A-Dataset.git
cd Deep_Convolutional_GAN-using-CELEB-A-Dataset
Prepare the CelebA dataset by placing the images in the CelebA_Dataset directory.

Train the DCGAN model:

bash
Copy code
python dcgan.py
After training, generated images will be saved in the results folder.

Sample Generated Images
Here is an example of a generated image after training:


Conclusion
This project demonstrates the capabilities of Generative Adversarial Networks (GANs), specifically DCGANs, in generating realistic images of celebrity faces. The generator network continuously improves as it learns to create images that closely resemble real faces, while the discriminator helps refine this process.

Acknowledgments
Rohan Paul for his original DCGAN implementation and tutorial, which provided the foundation for this project. His tutorial is available here.
The TensorFlow community for providing a powerful framework to build and train deep learning models.
```bash
